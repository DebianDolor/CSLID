{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "import sklearn.metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset generated by CovaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_macro_tpr_fpr(voting_cm):\n",
    "    num_classes = voting_cm.shape[0]\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        TP = voting_cm[i, i]\n",
    "        FN = np.sum(voting_cm[i, :]) - TP\n",
    "        FP = np.sum(voting_cm[:, i]) - TP\n",
    "        TN = np.sum(voting_cm) - (TP + FN + FP)\n",
    "\n",
    "        TPR = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "        tpr_list.append(TPR)\n",
    "        fpr_list.append(FPR)\n",
    "\n",
    "    macro_tpr = np.mean(tpr_list)\n",
    "    macro_fpr = np.mean(fpr_list)\n",
    "\n",
    "    return macro_tpr, macro_fpr\n",
    "\n",
    "train = pd.read_csv('/home/vvhoang/new/full_code/DS/train_shap_52.csv')\n",
    "test = pd.read_csv('/home/vvhoang/new/full_code/DS/test_shap_52.csv')\n",
    "\n",
    "X_train = train.drop(['Label'], axis=1)\n",
    "y_train = train['Label']\n",
    "X_test = test.drop(['Label'], axis=1)\n",
    "y_test = test['Label']\n",
    "y_test = pd.Series(y_test)\n",
    "y_train = pd.Series(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier Starting\n",
      "XGBClassifier Finished\n",
      "XGBoost report:\n",
      "XGBoost Time: 0.148360013961792\n",
      "XGBoost Accuracy: 0.8427021696252466\n",
      "XGBoost Precision: 0.8427021696252466\n",
      "XGBoost F1: 0.8427021696252466\n",
      "XGBoost Recall: 0.8427021696252466\n",
      "XGBoost FP 0\n",
      "XGBoost CM: [[169   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 169   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0 169   0   0   0   0  42   0  10   0   0]\n",
      " [  0   0   0 169   0   0   0   3   0   0   0   0]\n",
      " [  0   0   0   0 169   1   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0 168   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 169   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  55  40   5   0   0]\n",
      " [  0   0   0   0   0   0   0  49 129   0   0   0]\n",
      " [  0   0   0   0   0   0   0   6   0  92  87   0]\n",
      " [  0   0   0   0   0   0   0  10   0  62  82   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 169]]\n",
      "XGBoost Macro-average TPR: 0.8352117822023984\n",
      "XGBoost Macro-average FPR: 0.014124362800583922\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'device': 'cuda',\n",
    "    'max_depth': 128,\n",
    "    'n_estimators': 5000,\n",
    "    'objective':\"multi:softmax\", \n",
    "    'num_class':len(y_train.unique())  ,\n",
    "    'booster': 'gbtree',\n",
    "    'learning_rate': 0.1,\n",
    "    'eval_metric': 'auc',\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "\n",
    "print(\"XGBClassifier Starting\")\n",
    "xgb_model = XGBClassifier(**xgb_params)\n",
    "# xgb_model = joblib.load('./models/framework_xgb_best.pkl')\n",
    "xgb_model.fit(X_train,y_train)\n",
    "joblib.dump(xgb_model, './models/framework_xgb_best.pkl')\n",
    "xgb_start_time = time.time()\n",
    "xgb_prediction = xgb_model.predict(X_test)\n",
    "xgb_end_time = time.time()\n",
    "xgb_time = xgb_end_time - xgb_start_time\n",
    "print(\"XGBClassifier Finished\")\n",
    "\n",
    "xgb_acc = sklearn.metrics.accuracy_score(xgb_prediction, y_test)\n",
    "xgb_precision = sklearn.metrics.precision_score(xgb_prediction, y_test, average='micro')\n",
    "xgb_f1 = sklearn.metrics.f1_score(xgb_prediction, y_test, average='micro')\n",
    "xgb_recall = sklearn.metrics.recall_score(xgb_prediction, y_test, average='micro')\n",
    "xgb_cm = sklearn.metrics.confusion_matrix(xgb_prediction, y_test)\n",
    "xgb_fp = xgb_cm[0, 1]\n",
    "print(\"XGBoost report:\")\n",
    "print(\"XGBoost Time:\", xgb_time)\n",
    "print(\"XGBoost Accuracy:\", xgb_acc)\n",
    "print(\"XGBoost Precision:\", xgb_precision)\n",
    "print(\"XGBoost F1:\", xgb_f1)\n",
    "print(\"XGBoost Recall:\", xgb_recall)\n",
    "print(\"XGBoost FP\", xgb_fp)\n",
    "print(\"XGBoost CM:\", xgb_cm)\n",
    "xgb_tpr, xgb_fpr = calculate_macro_tpr_fpr(xgb_cm)\n",
    "print(f'XGBoost Macro-average TPR: {xgb_tpr}')\n",
    "print(f'XGBoost Macro-average FPR: {xgb_fpr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier Starting\n",
      "ExtraTreesClassifier Finished\n",
      "ExtraTrees report:\n",
      "ExtraTrees Time: 0.10711264610290527\n",
      "ExtraTrees Accuracy: 0.8550295857988166\n",
      "ExtraTrees Precision: 0.8550295857988166\n",
      "ExtraTrees F1: 0.8550295857988166\n",
      "ExtraTrees Recall: 0.8550295857988166\n",
      "ExtraTrees FP: 0\n",
      "ExtraTrees CM:\n",
      " [[169   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 169   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0 169   0   0   0   0  27   0  11   0   0]\n",
      " [  0   0   0 169   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 169   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 169   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 169   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  83  37   5   0   0]\n",
      " [  0   0   0   0   0   0   0  36 132   0   0   0]\n",
      " [  0   0   0   0   0   0   0   9   0  94  96   0]\n",
      " [  0   0   0   0   0   0   0  13   0  59  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 169]]\n",
      "XGBoost Macro-average TPR: 0.8530055948711128\n",
      "XGBoost Macro-average FPR: 0.013089397043769177\n"
     ]
    }
   ],
   "source": [
    "et_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_leaf_nodes\": 15000,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 0,\n",
    "    \"bootstrap\": True,\n",
    "    \"criterion\": \"entropy\"\n",
    "}\n",
    "\n",
    "print(\"ExtraTreesClassifier Starting\")\n",
    "et_model = ExtraTreesClassifier(**et_params)\n",
    "# et_model = joblib.load('./models/framework_et_best.pkl')\n",
    "et_model.fit(X=X_train, y=y_train)\n",
    "joblib.dump(et_model, './models/framework_et_best.pkl')\n",
    "et_start_time = time.time()\n",
    "et_prediction = et_model.predict(X_test)\n",
    "et_end_time = time.time()\n",
    "et_time = et_end_time - et_start_time\n",
    "print(\"ExtraTreesClassifier Finished\")\n",
    "\n",
    "et_acc = sklearn.metrics.accuracy_score(et_prediction, y_test)\n",
    "et_precision = sklearn.metrics.precision_score(et_prediction, y_test, average='micro')\n",
    "et_f1 = sklearn.metrics.f1_score(et_prediction, y_test, average='micro')\n",
    "et_recall = sklearn.metrics.recall_score(et_prediction, y_test, average='micro')\n",
    "et_cm = sklearn.metrics.confusion_matrix(et_prediction, y_test)\n",
    "et_fp = et_cm[0, 1]\n",
    "print(\"ExtraTrees report:\")\n",
    "print(\"ExtraTrees Time:\", et_end_time - et_start_time)\n",
    "print(\"ExtraTrees Accuracy:\", et_acc)\n",
    "print(\"ExtraTrees Precision:\", et_precision)\n",
    "print(\"ExtraTrees F1:\", et_f1)\n",
    "print(\"ExtraTrees Recall:\", et_recall)\n",
    "print(\"ExtraTrees FP:\", et_fp)\n",
    "print(\"ExtraTrees CM:\\n\", et_cm)\n",
    "et_tpr, et_fpr = calculate_macro_tpr_fpr(et_cm)\n",
    "print(f'XGBoost Macro-average TPR: {et_tpr}')\n",
    "print(f'XGBoost Macro-average FPR: {et_fpr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Starting\n",
      "RandomForestClassifier Finished\n",
      "RandomForest report:\n",
      "RandomForest Time: 0.3634300231933594\n",
      "RandomForest Accuracy: 0.8451676528599605\n",
      "RandomForest Precision: 0.8451676528599605\n",
      "RandomForest F1: 0.8451676528599605\n",
      "RandomForest Recall: 0.8451676528599605\n",
      "RandomForest FP: 0\n",
      "RandomForest CM: [[169   0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0 169   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0 169   0   0   0   0  36   0  12   0   0]\n",
      " [  0   0   0 169   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0 169   1   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0 168   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 169   3   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  71  42   5   1   0]\n",
      " [  0   0   0   0   0   0   0  31 127   0   0   0]\n",
      " [  0   0   0   0   0   0   0  10   0  97 100   0]\n",
      " [  0   0   0   0   0   0   0  12   0  55  68   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 169]]\n",
      "XGBoost Macro-average TPR: 0.8411108665069027\n",
      "XGBoost Macro-average FPR: 0.013935540346394203\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    \"n_estimators\": 900,\n",
    "    \"max_leaf_nodes\": 15000,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 0,\n",
    "    \"bootstrap\": True,\n",
    "    \"criterion\": \"entropy\"\n",
    "}\n",
    "\n",
    "print(\"RandomForestClassifier Starting\")\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "# rf_model = joblib.load('./models/framework_rf_best.pkl')\n",
    "rf_model.fit(X=X_train, y=y_train)\n",
    "joblib.dump(rf_model, './models/framework_rf_best.pkl')\n",
    "rf_start_time = time.time()\n",
    "rf_prediction = rf_model.predict(X_test)\n",
    "rf_end_time = time.time()\n",
    "rf_time = rf_end_time - rf_start_time\n",
    "print(\"RandomForestClassifier Finished\")\n",
    "\n",
    "rf_acc = sklearn.metrics.accuracy_score(rf_prediction, y_test)\n",
    "rf_precision = sklearn.metrics.precision_score(rf_prediction, y_test, average='micro')\n",
    "rf_f1 = sklearn.metrics.f1_score(rf_prediction, y_test, average='micro')\n",
    "rf_recall = sklearn.metrics.recall_score(rf_prediction, y_test, average='micro')\n",
    "rf_cm = sklearn.metrics.confusion_matrix(rf_prediction, y_test)\n",
    "rf_fp = rf_cm[0, 1]\n",
    "print(\"RandomForest report:\")\n",
    "print(\"RandomForest Time:\", rf_end_time - rf_start_time)\n",
    "print(\"RandomForest Accuracy:\", rf_acc)\n",
    "print(\"RandomForest Precision:\", rf_precision)\n",
    "print(\"RandomForest F1:\", rf_f1)\n",
    "print(\"RandomForest Recall:\", rf_recall)\n",
    "print(\"RandomForest FP:\", rf_fp)\n",
    "print(\"RandomForest CM:\", rf_cm)\n",
    "rf_tpr, rf_fpr = calculate_macro_tpr_fpr(rf_cm)\n",
    "print(f'XGBoost Macro-average TPR: {rf_tpr}')\n",
    "print(f'XGBoost Macro-average FPR: {rf_fpr}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
